{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.backends import cudnn\n",
    "from torch import optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Easy Implementation of InfoGAN')\n",
    "\n",
    "# model hyper-parameters\n",
    "parser.add_argument('--image_size', type=int, default=128) # 32 for kpc32\n",
    "parser.add_argument('--z_dim', type=int, default=2) #\n",
    "parser.add_argument('--featu_dim', type=int, default=2) #\n",
    "\n",
    "# training hyper-parameters\n",
    "parser.add_argument('--num_epochs', type=int, default=5) # 30 or 50 for MNIST / 4 for CelebA\n",
    "parser.add_argument('--test_epochs', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--num_workers', type=int, default=2)\n",
    "parser.add_argument('--lrD', type=float, default=0.0005) # Learning Rate for D\n",
    "parser.add_argument('--lrG', type=float, default=0.0005) # Learning Rate for G\n",
    "parser.add_argument('--beta1', type=float, default=0.5)  # momentum1 in Adam\n",
    "parser.add_argument('--beta2', type=float, default=0.999)  # momentum2 in Adam\n",
    "\n",
    "# InfoGAN parameters\n",
    "parser.add_argument('--cc_dim', type=int, default=1)\n",
    "parser.add_argument('--dc_dim', type=int, default=3)# class\n",
    "parser.add_argument('--continuous_weight', type=float, default=1.0) # 0.1~0.5 for MNIST / 1.0 for CelebA\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--db', type=str, default='kpc128')  # Model Tmp Save\n",
    "parser.add_argument('--model_g_path', type=str, default='./models/models_g_128')  # Model Tmp Save\n",
    "parser.add_argument('--model_d_path', type=str, default='./models/models_d_128')  # Model Tmp Save\n",
    "parser.add_argument('--model_c_path', type=str, default='./models/models_c_128')  # Model Tmp Save\n",
    "parser.add_argument('--sample_path', type=str, default='./results/result_128')  # Results\n",
    "parser.add_argument('--sample_path_2', type=str, default='./results')  # Results\n",
    "parser.add_argument('--sample_size', type=int, default=30) #5 class * 10列\n",
    "parser.add_argument('--log_step', type=int, default=100)\n",
    "parser.add_argument('--sample_step', type=int, default=100)\n",
    "args = parser.parse_args(\"\")  #remember this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, db='kpc128', z_dim=32, cc_dim = 1, dc_dim=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.db = db\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(cc_dim + dc_dim + z_dim, 8*16*16),\n",
    "            nn.BatchNorm1d(8*16*16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv = nn.Sequential(               \n",
    "            nn.ConvTranspose2d(8,64,4,2,1),#[16 to 32]\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64,128,4,2,1),#[32 to 64]\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(128,3,4,2,1),#[64 to 128]\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        z = self.fc( z )\n",
    "        z = z.view(-1, 8, 16, 16)\n",
    "        out = self.conv(z)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, db='kpc128', featu_dim = args.featu_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.db = db\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 4, 2, 1), # [128 to 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 64, 4, 2, 1), #[64 to 32]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 32, 4, 2, 1), #[32 to 16]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, 16, 4, 2, 1), #[16 to 8]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*8*8, featu_dim),\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(featu_dim, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        tmp = self.conv(x)\n",
    "        tmp = tmp.view(-1, 16*8*8)\n",
    "        featu = self.fc(tmp)\n",
    "        out = self.fc2(featu)\n",
    "        \n",
    "        # Discrimination Output\n",
    "        out[:, 0] = F.sigmoid(out[:, 0].clone()) #take the first value as the class. sigmoid for binary classify: real(1) or fake(0)\n",
    "\n",
    "        return out, featu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module): # net Q\n",
    "    def __init__(self, db='kpc128', cc_dim = args.cc_dim, dc_dim = args.dc_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.db = db\n",
    "        self.cc_dim = cc_dim\n",
    "        self.dc_dim = dc_dim\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 4, 2, 1), # [128 to 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 64, 4, 2, 1), #[64 to 32]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 32, 4, 2, 1), #[32 to 16]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, 16, 4, 2, 1), #[16 to 8]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*8*8, cc_dim + dc_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        tmp = self.conv(x)\n",
    "        tmp = tmp.view(-1, 16*8*8)\n",
    "        out = self.fc(tmp)\n",
    "        \n",
    "        #out[:, self.cc_dim:self.cc_dim+self.dc_dim] = F.softmax(out[:, self.cc_dim:self.cc_dim+self.dc_dim].clone())\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16827, 128, 128, 3)\n",
      "(16827, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale((args.image_size, args.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5, ))])\n",
    "\n",
    "dataset=np.load(\"./kpc/data1/128.npy\")\n",
    "print(dataset.shape)\n",
    "dataset = np.moveaxis(dataset, 3, 1)\n",
    "print(dataset.shape)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                                batch_size=args.batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load data--\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Scale((args.image_size, args.image_size)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5, ))])\n",
    "\n",
    "# if args.db=='kpc128': # kpc64\n",
    "#     #dataset = ImageFolder(args.image_path, transform)# modify the path\n",
    "#     dataset = np.load(\"./kpc/data0/slice128_Block2_11K.npy\")\n",
    "#     print(dataset.shape)####################\n",
    "#     dataset = dataset[:, 0, :, :, :]\n",
    "#     dataset = np.moveaxis(dataset, 3, 1)\n",
    "#     print(dataset.shape)\n",
    "#     dataset.astype(float)\n",
    "#     dataset = dataset/255\n",
    "#     dataset = torch.from_numpy(dataset)\n",
    "#     #dataset = dataset.to(device)\n",
    "#     print(dataset.shape)\n",
    "# #dataloader = torch.utils.DataLoader(dataset)\n",
    "    \n",
    "# data_loader = data.DataLoader(dataset=dataset,\n",
    "#                                 batch_size=args.batch_size,\n",
    "#                                 shuffle=True,\n",
    "#                                 num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_variable(x): # use GPU\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "# InfoGAN Function (Gaussian)\n",
    "def gen_cc(n_size, dim):\n",
    "    return torch.Tensor(np.random.randn(n_size, dim)*0.5)\n",
    "\n",
    "# InfoGAN Function (Multi-Nomial)\n",
    "def gen_dc(n_size, dim):\n",
    "    codes=[]\n",
    "    code = np.zeros((n_size, dim))\n",
    "    random_cate = np.random.randint(0, dim, n_size)\n",
    "    code[range(n_size), random_cate] = 1\n",
    "    codes.append(code)\n",
    "    codes = np.concatenate(codes,1)\n",
    "    return torch.Tensor(codes)\n",
    "\n",
    "LAMBDA = 1 # Gradient penalty lambda hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import random\n",
    "# #-------Fixed noise----\n",
    "# mmm = int(args.sample_size / 10)\n",
    "# print(mmm)\n",
    "\n",
    "# empty = torch.full((1, args.z_dim), 1)\n",
    "# ten_empty = torch.full((1,args.z_dim), 1)\n",
    "\n",
    "# for x in range(mmm):\n",
    "#     one_row = torch.rand(1,args.z_dim)\n",
    "\n",
    "#     for i in range(10):\n",
    "#         empty = torch.cat((empty, one_row), 0) \n",
    "\n",
    "# ten_empty = torch.cat((ten_empty, empty), 0)\n",
    "\n",
    "# ten_empty = ten_empty[torch.arange(ten_empty.size(0))!=0]\n",
    "# ten_empty = ten_empty[torch.arange(ten_empty.size(0))!=0]\n",
    "\n",
    "# print(ten_empty.shape)\n",
    "\n",
    "# #-----------------------------\n",
    "# fixed_noise = to_variable(ten_empty)\n",
    "# print(fixed_noise)\n",
    "# print(fixed_noise.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886],\n",
      "        [0.1323, 0.3396, 0.2601, 0.6886]], device='cuda:0')\n",
      "torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "#-------Fixed noise----\n",
    "empty = torch.full((1, args.z_dim), 1)\n",
    "one_row = torch.rand(1,args.z_dim)\n",
    "for x in range(args.sample_size):\n",
    "    empty = torch.cat((empty, one_row), 0)\n",
    "empty = empty[torch.arange(empty.size(0))!=0]\n",
    "#print(empty.shape, empty)\n",
    "fixed_noise = to_variable(empty)\n",
    "print(fixed_noise)\n",
    "print(fixed_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === entropy compute === #\n",
    "def get_binary_KLD(pp, qq, batch_mean=True):\n",
    "    tmp = torch.sum( (pp*(torch.log(pp+1e-8)-torch.log(qq+1e-8)) + (1-pp)*(torch.log(1-pp+1e-8)-torch.log(1-qq+1e-8))), dim=1)\n",
    "    if(batch_mean):\n",
    "        return(torch.mean(tmp))\n",
    "    else:\n",
    "        return(tmp)\n",
    "\n",
    "def get_binary_cross_entropy(ppp, qqq):\n",
    "    sss = -ppp*torch.log(qqq+1e-8) -(1-ppp)*torch.log(1-qqq+1e-8)\n",
    "    return(torch.sum(sss, dim=1))\n",
    "\n",
    "def get_binary_entropy(ppp):\n",
    "    sss = -ppp*torch.log(ppp+1e-8) -(1-ppp)*torch.log(1-ppp+1e-8)\n",
    "    return(torch.sum(sss, dim=1))\n",
    "\n",
    "def get_entropy_1D(xxx):\n",
    "    return( -torch.sum(xxx * torch.log(xxx + 1e-8)) )\n",
    "\n",
    "def get_entropy_2D(xxx):\n",
    "    return( -torch.sum(xxx * torch.log(xxx + 1e-8), dim=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.5, beta2=0.999, cc_dim=1, continuous_weight=1.0, db='kpc128', dc_dim=3, featu_dim=2, image_size=128, log_step=100, lrD=0.0005, lrG=0.0005, model_c_path='./models/models_c_128', model_d_path='./models/models_d_128', model_g_path='./models/models_g_128', num_epochs=5, num_workers=2, sample_path='./results/result_128', sample_path_2='./results', sample_size=30, sample_step=100, test_epochs=1, z_dim=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ffe89109edd5>:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  fake_featu = F.log_softmax(fake_featu)\n",
      "<ipython-input-30-ffe89109edd5>:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sof_noice = F.softmax(noise)\n",
      "<ipython-input-30-ffe89109edd5>:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  real_featu = F.softmax(real_featu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dc0 tensor([0, 2, 0, 2, 2, 1, 2, 1], device='cuda:0') dc_0 tensor([0, 2, 0, 2, 2, 1, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 0, 0, 1, 1, 0, 0], device='cuda:0') mse tensor(0.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[100/2104], d_loss: 0.0149, c_loss: 0.0232, g_loss: 4.8319, g_loss_a: 4.8153, KL_F&N: 5.4993, KL_F&R: 9.4911, entropy_marginal: -3.0934, entropy_mean: -8.2840\n",
      "output_dc0 tensor([1, 2, 2, 1, 2, 1, 0, 0], device='cuda:0') dc_0 tensor([1, 2, 2, 1, 2, 1, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 1, 2, 0, 2, 0, 0], device='cuda:0') mse tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[200/2104], d_loss: 1.0562, c_loss: 0.1025, g_loss: 1.9584, g_loss_a: 1.9220, KL_F&N: 0.1126, KL_F&R: 0.6800, entropy_marginal: -2.8061, entropy_mean: -6.6253\n",
      "output_dc0 tensor([0, 1, 1, 1, 1, 2, 0, 2], device='cuda:0') dc_0 tensor([0, 1, 1, 1, 1, 2, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 1, 2, 2, 0, 0, 2], device='cuda:0') mse tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[300/2104], d_loss: 0.7986, c_loss: 0.0512, g_loss: 1.4693, g_loss_a: 1.4512, KL_F&N: 1.2517, KL_F&R: 1.3127, entropy_marginal: -5.6797, entropy_mean: -11.7184\n",
      "output_dc0 tensor([1, 1, 0, 0, 0, 2, 2, 1], device='cuda:0') dc_0 tensor([1, 1, 0, 0, 0, 2, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 2, 2, 2, 0, 0, 0], device='cuda:0') mse tensor(0.1490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[400/2104], d_loss: 1.1222, c_loss: 0.0020, g_loss: 2.0092, g_loss_a: 2.0073, KL_F&N: 0.3481, KL_F&R: 0.5770, entropy_marginal: -7.5652, entropy_mean: -14.9217\n",
      "output_dc0 tensor([1, 1, 1, 2, 1, 0, 1, 0], device='cuda:0') dc_0 tensor([1, 1, 1, 2, 1, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 0, 1, 1, 2, 2, 1], device='cuda:0') mse tensor(0.2865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[500/2104], d_loss: 1.0280, c_loss: 0.0139, g_loss: 0.9169, g_loss_a: 0.9077, KL_F&N: 0.7607, KL_F&R: 0.5792, entropy_marginal: -7.9842, entropy_mean: -13.0466\n",
      "output_dc0 tensor([0, 1, 0, 2, 1, 0, 0, 0], device='cuda:0') dc_0 tensor([0, 1, 0, 2, 1, 0, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 2, 2, 1, 2, 1, 2], device='cuda:0') mse tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[600/2104], d_loss: 0.6290, c_loss: 0.0333, g_loss: 2.5458, g_loss_a: 2.5298, KL_F&N: 0.7589, KL_F&R: 1.6682, entropy_marginal: -9.1022, entropy_mean: -14.8149\n",
      "output_dc0 tensor([1, 1, 0, 2, 0, 0, 1, 0], device='cuda:0') dc_0 tensor([1, 1, 0, 2, 0, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 0, 1, 0, 0, 1, 2], device='cuda:0') mse tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[700/2104], d_loss: 0.4145, c_loss: 0.0150, g_loss: 3.0779, g_loss_a: 3.0707, KL_F&N: 0.9217, KL_F&R: 2.3398, entropy_marginal: -9.4691, entropy_mean: -16.6045\n",
      "output_dc0 tensor([1, 0, 2, 1, 2, 0, 1, 0], device='cuda:0') dc_0 tensor([1, 0, 2, 1, 2, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 2, 2, 2, 0, 2, 0], device='cuda:0') mse tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[800/2104], d_loss: 0.8543, c_loss: 0.0013, g_loss: 2.0637, g_loss_a: 2.0624, KL_F&N: 0.5475, KL_F&R: 1.0926, entropy_marginal: -10.6394, entropy_mean: -20.2839\n",
      "output_dc0 tensor([0, 2, 2, 0, 1, 1, 0, 2], device='cuda:0') dc_0 tensor([0, 2, 2, 0, 1, 1, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 1, 2, 0, 0, 0, 2], device='cuda:0') mse tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[900/2104], d_loss: 0.8943, c_loss: 0.0050, g_loss: 2.1418, g_loss_a: 2.1361, KL_F&N: 0.5397, KL_F&R: 0.7857, entropy_marginal: -9.6738, entropy_mean: -15.8182\n",
      "output_dc0 tensor([1, 0, 0, 1, 2, 1, 0, 1], device='cuda:0') dc_0 tensor([1, 0, 0, 1, 2, 1, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 1, 2, 2, 1, 1, 1], device='cuda:0') mse tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1000/2104], d_loss: 0.6818, c_loss: 0.0148, g_loss: 1.9481, g_loss_a: 1.9348, KL_F&N: 0.7179, KL_F&R: 1.2942, entropy_marginal: -10.9365, entropy_mean: -16.2854\n",
      "output_dc0 tensor([0, 2, 1, 1, 0, 2, 2, 2], device='cuda:0') dc_0 tensor([0, 2, 1, 1, 0, 2, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 1, 2, 1, 2, 0, 1], device='cuda:0') mse tensor(0.4087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1100/2104], d_loss: 0.9159, c_loss: 0.1290, g_loss: 0.8093, g_loss_a: 0.8047, KL_F&N: 1.0564, KL_F&R: 0.8596, entropy_marginal: -11.3496, entropy_mean: -19.0968\n",
      "output_dc0 tensor([0, 2, 2, 2, 1, 2, 2, 0], device='cuda:0') dc_0 tensor([0, 2, 2, 2, 1, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 2, 0, 2, 1, 1, 1], device='cuda:0') mse tensor(0.5028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1200/2104], d_loss: 0.4829, c_loss: 0.0089, g_loss: 1.7705, g_loss_a: 1.7632, KL_F&N: 0.6584, KL_F&R: 2.0791, entropy_marginal: -12.1974, entropy_mean: -19.6602\n",
      "output_dc0 tensor([1, 2, 0, 2, 0, 0, 1, 0], device='cuda:0') dc_0 tensor([1, 2, 0, 2, 0, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 2, 1, 0, 0, 1, 1], device='cuda:0') mse tensor(0.3441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1300/2104], d_loss: 0.8995, c_loss: 0.0043, g_loss: 2.1938, g_loss_a: 2.1907, KL_F&N: 0.5216, KL_F&R: 0.7330, entropy_marginal: -12.8791, entropy_mean: -21.3349\n",
      "output_dc0 tensor([1, 0, 2, 0, 0, 1, 0, 0], device='cuda:0') dc_0 tensor([1, 0, 2, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 0, 2, 1, 1, 1, 0], device='cuda:0') mse tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1400/2104], d_loss: 0.6543, c_loss: 0.0092, g_loss: 1.4797, g_loss_a: 1.4730, KL_F&N: 0.6395, KL_F&R: 1.2195, entropy_marginal: -13.5004, entropy_mean: -21.7880\n",
      "output_dc0 tensor([2, 0, 1, 0, 1, 1, 0, 0], device='cuda:0') dc_0 tensor([2, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 1, 0, 2, 0, 0], device='cuda:0') mse tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1500/2104], d_loss: 0.4880, c_loss: 0.0104, g_loss: 2.6239, g_loss_a: 2.6166, KL_F&N: 1.6339, KL_F&R: 2.0800, entropy_marginal: -12.3009, entropy_mean: -19.9201\n",
      "output_dc0 tensor([2, 1, 1, 1, 0, 2, 0, 1], device='cuda:0') dc_0 tensor([2, 1, 1, 1, 1, 2, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 0, 0, 2, 1, 2, 1], device='cuda:0') mse tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1600/2104], d_loss: 0.4594, c_loss: 0.1379, g_loss: 2.1006, g_loss_a: 2.0959, KL_F&N: 1.0510, KL_F&R: 1.7852, entropy_marginal: -13.3899, entropy_mean: -20.9193\n",
      "output_dc0 tensor([0, 2, 0, 1, 1, 1, 2, 2], device='cuda:0') dc_0 tensor([0, 2, 0, 1, 1, 1, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 2, 2, 0, 0, 2, 2], device='cuda:0') mse tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1700/2104], d_loss: 0.3518, c_loss: 0.0014, g_loss: 2.4636, g_loss_a: 2.4626, KL_F&N: 1.2779, KL_F&R: 2.3043, entropy_marginal: -12.5490, entropy_mean: -20.5023\n",
      "output_dc0 tensor([2, 0, 2, 1, 1, 1, 1, 0], device='cuda:0') dc_0 tensor([2, 0, 2, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 1, 1, 2, 1, 2, 2], device='cuda:0') mse tensor(0.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1800/2104], d_loss: 0.6133, c_loss: 0.0001, g_loss: 2.3937, g_loss_a: 2.3936, KL_F&N: 0.5253, KL_F&R: 1.0023, entropy_marginal: -14.2891, entropy_mean: -24.7290\n",
      "output_dc0 tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0') dc_0 tensor([1, 0, 0, 1, 2, 2, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 1, 1, 0, 2, 1], device='cuda:0') mse tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[1900/2104], d_loss: 0.5100, c_loss: 0.0025, g_loss: 2.0429, g_loss_a: 2.0406, KL_F&N: 0.5933, KL_F&R: 1.4769, entropy_marginal: -14.0232, entropy_mean: -22.1609\n",
      "output_dc0 tensor([2, 2, 2, 0, 2, 2, 0, 2], device='cuda:0') dc_0 tensor([2, 2, 2, 0, 2, 2, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 2, 0, 2, 2, 2, 1], device='cuda:0') mse tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[2000/2104], d_loss: 1.1689, c_loss: 0.0485, g_loss: 2.9680, g_loss_a: 2.9544, KL_F&N: 0.1807, KL_F&R: 0.3485, entropy_marginal: -16.5489, entropy_mean: -23.4097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dc0 tensor([2, 0, 1, 2, 0, 0, 0, 1], device='cuda:0') dc_0 tensor([2, 0, 1, 2, 0, 0, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 0, 1, 2, 2, 2, 2], device='cuda:0') mse tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[1/5],Step[2100/2104], d_loss: 0.8249, c_loss: 0.0257, g_loss: 2.5757, g_loss_a: 2.5679, KL_F&N: 0.3893, KL_F&R: 0.6842, entropy_marginal: -15.6734, entropy_mean: -25.5380\n",
      "output_dc0 tensor([0, 0, 2, 0, 0, 2, 1, 0], device='cuda:0') dc_0 tensor([0, 0, 2, 0, 0, 2, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 1, 1, 2, 1, 0, 0], device='cuda:0') mse tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[100/2104], d_loss: 0.5988, c_loss: 0.0004, g_loss: 2.3733, g_loss_a: 2.3730, KL_F&N: 0.9405, KL_F&R: 1.3810, entropy_marginal: -14.8266, entropy_mean: -23.5143\n",
      "output_dc0 tensor([0, 0, 1, 1, 1, 2, 1, 2], device='cuda:0') dc_0 tensor([0, 0, 1, 1, 1, 2, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 2, 2, 0, 1, 2], device='cuda:0') mse tensor(0.3375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[200/2104], d_loss: 1.3699, c_loss: 0.0030, g_loss: 0.6395, g_loss_a: 0.6370, KL_F&N: 1.3872, KL_F&R: 0.2266, entropy_marginal: -16.1170, entropy_mean: -26.8545\n",
      "output_dc0 tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0') dc_0 tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 0, 1, 1, 0, 2, 0], device='cuda:0') mse tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[300/2104], d_loss: 0.3387, c_loss: 0.0001, g_loss: 2.7107, g_loss_a: 2.7105, KL_F&N: 0.8458, KL_F&R: 2.0766, entropy_marginal: -22.0278, entropy_mean: -31.4015\n",
      "output_dc0 tensor([1, 0, 1, 2, 0, 0, 1, 1], device='cuda:0') dc_0 tensor([1, 0, 1, 2, 0, 0, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 1, 1, 1, 0, 1, 0], device='cuda:0') mse tensor(0.3044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[400/2104], d_loss: 0.4216, c_loss: 0.0004, g_loss: 2.2769, g_loss_a: 2.2766, KL_F&N: 0.6393, KL_F&R: 1.8320, entropy_marginal: -16.8277, entropy_mean: -28.0397\n",
      "output_dc0 tensor([1, 1, 1, 0, 1, 0, 2, 1], device='cuda:0') dc_0 tensor([1, 1, 1, 0, 1, 0, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 0, 2, 0, 0, 2, 0], device='cuda:0') mse tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[500/2104], d_loss: 0.6041, c_loss: 0.0883, g_loss: 1.4058, g_loss_a: 1.4033, KL_F&N: 0.9026, KL_F&R: 1.1671, entropy_marginal: -15.5070, entropy_mean: -23.8513\n",
      "output_dc0 tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0') dc_0 tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 1, 2, 2, 2, 0, 2], device='cuda:0') mse tensor(0.5253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[600/2104], d_loss: 0.6951, c_loss: 0.0024, g_loss: 1.8923, g_loss_a: 1.8902, KL_F&N: 0.5208, KL_F&R: 0.9535, entropy_marginal: -18.7309, entropy_mean: -27.0601\n",
      "output_dc0 tensor([2, 1, 2, 1, 2, 1, 0, 1], device='cuda:0') dc_0 tensor([2, 1, 2, 1, 2, 1, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 2, 0, 1, 1, 1, 2], device='cuda:0') mse tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[700/2104], d_loss: 0.9159, c_loss: 0.0005, g_loss: 3.1413, g_loss_a: 3.1408, KL_F&N: 0.1867, KL_F&R: 0.6329, entropy_marginal: -19.8552, entropy_mean: -30.5099\n",
      "output_dc0 tensor([0, 0, 1, 2, 2, 0, 1, 2], device='cuda:0') dc_0 tensor([0, 0, 1, 2, 2, 0, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 0, 0, 0, 2, 2, 0, 2], device='cuda:0') mse tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[800/2104], d_loss: 0.6517, c_loss: 0.0025, g_loss: 2.7331, g_loss_a: 2.7309, KL_F&N: 0.3730, KL_F&R: 0.8870, entropy_marginal: -15.6216, entropy_mean: -25.6722\n",
      "output_dc0 tensor([0, 0, 1, 0, 2, 0, 0, 0], device='cuda:0') dc_0 tensor([0, 0, 1, 0, 2, 0, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 1, 1, 1, 0, 2, 2], device='cuda:0') mse tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[900/2104], d_loss: 0.9220, c_loss: 0.0019, g_loss: 1.6006, g_loss_a: 1.5987, KL_F&N: 0.3093, KL_F&R: 0.6327, entropy_marginal: -16.9781, entropy_mean: -24.8445\n",
      "output_dc0 tensor([0, 1, 1, 0, 0, 1, 2, 0], device='cuda:0') dc_0 tensor([0, 1, 1, 0, 0, 1, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 1, 1, 1, 2, 0, 2], device='cuda:0') mse tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1000/2104], d_loss: 0.5382, c_loss: 0.0160, g_loss: 2.9667, g_loss_a: 2.9575, KL_F&N: 0.7497, KL_F&R: 1.4259, entropy_marginal: -19.1421, entropy_mean: -29.9395\n",
      "output_dc0 tensor([0, 1, 2, 0, 0, 1, 1, 2], device='cuda:0') dc_0 tensor([0, 1, 2, 0, 0, 1, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 0, 0, 0, 1, 2, 0], device='cuda:0') mse tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1100/2104], d_loss: 0.3253, c_loss: 0.0003, g_loss: 3.3779, g_loss_a: 3.3776, KL_F&N: 0.9927, KL_F&R: 2.1035, entropy_marginal: -18.6779, entropy_mean: -30.0700\n",
      "output_dc0 tensor([0, 0, 0, 2, 0, 2, 0, 1], device='cuda:0') dc_0 tensor([0, 0, 0, 2, 0, 2, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 0, 2, 2, 0, 0, 2], device='cuda:0') mse tensor(0.6713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1200/2104], d_loss: 0.4048, c_loss: 0.0009, g_loss: 1.8253, g_loss_a: 1.8243, KL_F&N: 1.3515, KL_F&R: 1.6830, entropy_marginal: -16.5940, entropy_mean: -27.9860\n",
      "output_dc0 tensor([0, 1, 0, 0, 0, 1, 1, 1], device='cuda:0') dc_0 tensor([0, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 0, 0, 1, 2, 0], device='cuda:0') mse tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1300/2104], d_loss: 0.8055, c_loss: 0.0003, g_loss: 3.9509, g_loss_a: 3.9507, KL_F&N: 0.3279, KL_F&R: 0.8567, entropy_marginal: -22.9629, entropy_mean: -32.3473\n",
      "output_dc0 tensor([1, 1, 1, 0, 2, 1, 1, 1], device='cuda:0') dc_0 tensor([1, 1, 1, 0, 2, 1, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 1, 0, 2, 0, 2, 0], device='cuda:0') mse tensor(0.4071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1400/2104], d_loss: 1.3659, c_loss: 0.0063, g_loss: 0.9742, g_loss_a: 0.9688, KL_F&N: 1.3983, KL_F&R: 0.7644, entropy_marginal: -19.4399, entropy_mean: -27.4438\n",
      "output_dc0 tensor([0, 0, 0, 2, 2, 0, 2, 1], device='cuda:0') dc_0 tensor([0, 0, 0, 2, 2, 0, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 2, 1, 1, 1, 0, 1], device='cuda:0') mse tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1500/2104], d_loss: 0.9306, c_loss: 0.0001, g_loss: 1.8217, g_loss_a: 1.8216, KL_F&N: 1.3663, KL_F&R: 1.3102, entropy_marginal: -21.1250, entropy_mean: -33.5417\n",
      "output_dc0 tensor([0, 0, 0, 2, 0, 2, 2, 0], device='cuda:0') dc_0 tensor([0, 0, 0, 2, 0, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0') mse tensor(0.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1600/2104], d_loss: 0.3550, c_loss: 0.0071, g_loss: 3.4660, g_loss_a: 3.4599, KL_F&N: 1.0503, KL_F&R: 1.5837, entropy_marginal: -17.3793, entropy_mean: -24.9205\n",
      "output_dc0 tensor([2, 1, 0, 1, 0, 0, 0, 1], device='cuda:0') dc_0 tensor([2, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 2, 1, 2, 1, 1], device='cuda:0') mse tensor(0.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1700/2104], d_loss: 0.9545, c_loss: 0.0129, g_loss: 4.6517, g_loss_a: 4.6447, KL_F&N: 0.3064, KL_F&R: 0.7802, entropy_marginal: -20.3952, entropy_mean: -33.4258\n",
      "output_dc0 tensor([1, 0, 1, 0, 0, 0, 2, 0], device='cuda:0') dc_0 tensor([1, 0, 1, 0, 0, 0, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0') mse tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1800/2104], d_loss: 0.4299, c_loss: 0.0540, g_loss: 3.3871, g_loss_a: 3.3773, KL_F&N: 1.1282, KL_F&R: 1.8779, entropy_marginal: -14.5950, entropy_mean: -23.7098\n",
      "output_dc0 tensor([1, 1, 0, 2, 0, 2, 0, 1], device='cuda:0') dc_0 tensor([1, 1, 0, 2, 0, 2, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 2, 2, 0, 0, 2, 2], device='cuda:0') mse tensor(0.3622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[1900/2104], d_loss: 0.7537, c_loss: 0.0003, g_loss: 2.4522, g_loss_a: 2.4519, KL_F&N: 1.0732, KL_F&R: 0.9379, entropy_marginal: -16.9778, entropy_mean: -27.5512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dc0 tensor([1, 1, 2, 1, 1, 1, 2, 2], device='cuda:0') dc_0 tensor([1, 1, 2, 1, 1, 1, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 2, 2, 0, 2, 2, 2], device='cuda:0') mse tensor(0.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[2000/2104], d_loss: 0.3161, c_loss: 0.0547, g_loss: 3.8972, g_loss_a: 3.8936, KL_F&N: 1.1003, KL_F&R: 1.8986, entropy_marginal: -19.3260, entropy_mean: -26.7085\n",
      "output_dc0 tensor([2, 1, 0, 0, 1, 0, 0, 1], device='cuda:0') dc_0 tensor([2, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 2, 0, 0, 2, 2], device='cuda:0') mse tensor(0.5924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[2/5],Step[2100/2104], d_loss: 0.7514, c_loss: 0.0021, g_loss: 0.9571, g_loss_a: 0.9555, KL_F&N: 1.0925, KL_F&R: 1.4178, entropy_marginal: -22.5501, entropy_mean: -35.1107\n",
      "output_dc0 tensor([1, 1, 2, 0, 0, 1, 1, 0], device='cuda:0') dc_0 tensor([1, 1, 2, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 0, 1, 1, 0, 1, 0, 2], device='cuda:0') mse tensor(0.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[100/2104], d_loss: 0.3979, c_loss: 0.0005, g_loss: 2.9694, g_loss_a: 2.9690, KL_F&N: 1.0036, KL_F&R: 1.7087, entropy_marginal: -21.0950, entropy_mean: -32.3007\n",
      "output_dc0 tensor([1, 1, 1, 1, 2, 2, 2, 1], device='cuda:0') dc_0 tensor([1, 1, 1, 1, 2, 2, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 1, 2, 0, 0, 1, 2], device='cuda:0') mse tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[200/2104], d_loss: 1.7989, c_loss: 0.0242, g_loss: 0.8559, g_loss_a: 0.8468, KL_F&N: 1.1555, KL_F&R: 0.1356, entropy_marginal: -20.3466, entropy_mean: -26.8224\n",
      "output_dc0 tensor([1, 2, 1, 1, 2, 2, 0, 0], device='cuda:0') dc_0 tensor([1, 2, 1, 1, 2, 2, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 0, 1, 1, 0, 0, 0], device='cuda:0') mse tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[300/2104], d_loss: 1.0726, c_loss: 0.0763, g_loss: 1.7600, g_loss_a: 1.7575, KL_F&N: 0.3704, KL_F&R: 0.5722, entropy_marginal: -22.1377, entropy_mean: -36.0549\n",
      "output_dc0 tensor([0, 2, 2, 2, 2, 2, 2, 1], device='cuda:0') dc_0 tensor([0, 2, 2, 2, 2, 2, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 0, 0, 2, 0, 0, 0], device='cuda:0') mse tensor(0.4650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[400/2104], d_loss: 0.1044, c_loss: 0.0026, g_loss: 4.6735, g_loss_a: 4.6711, KL_F&N: 1.1555, KL_F&R: 2.5123, entropy_marginal: -19.1974, entropy_mean: -26.1997\n",
      "output_dc0 tensor([0, 1, 2, 2, 0, 1, 0, 2], device='cuda:0') dc_0 tensor([0, 1, 2, 2, 0, 1, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 0, 2, 1, 0, 1, 1], device='cuda:0') mse tensor(0.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[500/2104], d_loss: 0.1843, c_loss: 0.0001, g_loss: 3.4231, g_loss_a: 3.4230, KL_F&N: 1.1368, KL_F&R: 2.7015, entropy_marginal: -18.3304, entropy_mean: -30.6200\n",
      "output_dc0 tensor([0, 1, 2, 2, 2, 2, 1, 1], device='cuda:0') dc_0 tensor([0, 1, 2, 2, 2, 2, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 0, 1, 2, 0, 2, 0], device='cuda:0') mse tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[600/2104], d_loss: 0.6781, c_loss: 0.0002, g_loss: 1.8792, g_loss_a: 1.8790, KL_F&N: 1.0134, KL_F&R: 1.4871, entropy_marginal: -25.4488, entropy_mean: -38.2509\n",
      "output_dc0 tensor([0, 0, 2, 0, 1, 0, 2, 0], device='cuda:0') dc_0 tensor([0, 0, 2, 0, 1, 0, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 1, 2, 1, 2, 0], device='cuda:0') mse tensor(0.4930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[700/2104], d_loss: 0.4740, c_loss: 0.0037, g_loss: 3.0321, g_loss_a: 3.0292, KL_F&N: 1.0418, KL_F&R: 1.4686, entropy_marginal: -19.8129, entropy_mean: -28.5936\n",
      "output_dc0 tensor([1, 1, 0, 1, 2, 0, 0, 2], device='cuda:0') dc_0 tensor([1, 1, 0, 1, 2, 0, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 0, 2, 0, 1, 2, 1], device='cuda:0') mse tensor(0.2732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[800/2104], d_loss: 0.9416, c_loss: 0.0001, g_loss: 1.8140, g_loss_a: 1.8139, KL_F&N: 0.4783, KL_F&R: 0.6041, entropy_marginal: -19.4353, entropy_mean: -31.2817\n",
      "output_dc0 tensor([1, 2, 2, 2, 2, 0, 1, 2], device='cuda:0') dc_0 tensor([1, 2, 2, 2, 2, 0, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 1, 2, 0, 2, 0], device='cuda:0') mse tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[900/2104], d_loss: 0.2265, c_loss: 0.0001, g_loss: 3.0983, g_loss_a: 3.0982, KL_F&N: 1.0512, KL_F&R: 2.0520, entropy_marginal: -21.1968, entropy_mean: -31.4050\n",
      "output_dc0 tensor([1, 1, 0, 2, 0, 0, 1, 2], device='cuda:0') dc_0 tensor([1, 1, 0, 2, 0, 0, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 2, 0, 0, 1, 1, 2], device='cuda:0') mse tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1000/2104], d_loss: 0.6808, c_loss: 0.0007, g_loss: 1.9651, g_loss_a: 1.9643, KL_F&N: 0.8225, KL_F&R: 1.3151, entropy_marginal: -20.3183, entropy_mean: -33.6197\n",
      "output_dc0 tensor([2, 2, 1, 0, 2, 1, 2, 2], device='cuda:0') dc_0 tensor([2, 2, 1, 0, 2, 1, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 2, 2, 2, 1, 2, 1], device='cuda:0') mse tensor(0.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1100/2104], d_loss: 0.2267, c_loss: 0.0003, g_loss: 2.9917, g_loss_a: 2.9914, KL_F&N: 0.7857, KL_F&R: 1.8224, entropy_marginal: -21.4504, entropy_mean: -31.0215\n",
      "output_dc0 tensor([0, 2, 1, 2, 2, 0, 1, 2], device='cuda:0') dc_0 tensor([0, 2, 1, 2, 2, 0, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 0, 2, 0, 0, 2, 2], device='cuda:0') mse tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1200/2104], d_loss: 0.7815, c_loss: 0.0001, g_loss: 5.0149, g_loss_a: 5.0149, KL_F&N: 0.1176, KL_F&R: 0.5733, entropy_marginal: -19.2380, entropy_mean: -32.2876\n",
      "output_dc0 tensor([1, 0, 0, 0, 1, 2, 2, 1], device='cuda:0') dc_0 tensor([1, 0, 0, 0, 1, 2, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 0, 2, 0, 0, 2, 1], device='cuda:0') mse tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1300/2104], d_loss: 0.2489, c_loss: 0.0000, g_loss: 2.4057, g_loss_a: 2.4057, KL_F&N: 0.4708, KL_F&R: 1.3785, entropy_marginal: -19.6348, entropy_mean: -33.3562\n",
      "output_dc0 tensor([2, 2, 0, 0, 0, 1, 1, 1], device='cuda:0') dc_0 tensor([2, 2, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 2, 1, 2, 1, 2, 1], device='cuda:0') mse tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1400/2104], d_loss: 0.4660, c_loss: 0.0000, g_loss: 2.0872, g_loss_a: 2.0871, KL_F&N: 1.0919, KL_F&R: 1.3576, entropy_marginal: -22.5798, entropy_mean: -37.4061\n",
      "output_dc0 tensor([0, 0, 1, 1, 0, 2, 2, 1], device='cuda:0') dc_0 tensor([0, 0, 1, 1, 0, 2, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 1, 1, 2, 1, 0, 1], device='cuda:0') mse tensor(0.3133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1500/2104], d_loss: 0.3052, c_loss: 0.0000, g_loss: 2.4866, g_loss_a: 2.4866, KL_F&N: 1.0761, KL_F&R: 1.5924, entropy_marginal: -20.1175, entropy_mean: -33.6125\n",
      "output_dc0 tensor([0, 1, 2, 1, 2, 0, 0, 0], device='cuda:0') dc_0 tensor([0, 1, 2, 1, 2, 0, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 2, 0, 1, 2, 0, 0], device='cuda:0') mse tensor(0.5370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1600/2104], d_loss: 0.1572, c_loss: 0.0041, g_loss: 3.1388, g_loss_a: 3.1356, KL_F&N: 1.1878, KL_F&R: 2.3198, entropy_marginal: -19.7457, entropy_mean: -31.5277\n",
      "output_dc0 tensor([1, 2, 2, 2, 2, 2, 2, 1], device='cuda:0') dc_0 tensor([1, 2, 2, 2, 2, 2, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 2, 1, 2, 2, 2, 2], device='cuda:0') mse tensor(0.4772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1700/2104], d_loss: 0.1547, c_loss: 0.0439, g_loss: 4.1648, g_loss_a: 4.1509, KL_F&N: 0.9530, KL_F&R: 2.1971, entropy_marginal: -18.3812, entropy_mean: -25.3946\n",
      "output_dc0 tensor([0, 2, 0, 1, 1, 1, 2, 1], device='cuda:0') dc_0 tensor([0, 2, 0, 1, 1, 1, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 2, 0, 1, 1, 0, 0], device='cuda:0') mse tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1800/2104], d_loss: 0.2311, c_loss: 0.0004, g_loss: 5.8514, g_loss_a: 5.8510, KL_F&N: 0.7879, KL_F&R: 1.8904, entropy_marginal: -20.1142, entropy_mean: -32.6833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dc0 tensor([0, 1, 0, 0, 1, 2, 2, 2], device='cuda:0') dc_0 tensor([0, 1, 0, 0, 1, 2, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 2, 0, 2, 1, 2], device='cuda:0') mse tensor(0.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[1900/2104], d_loss: 0.4503, c_loss: 0.0000, g_loss: 2.5845, g_loss_a: 2.5845, KL_F&N: 0.5405, KL_F&R: 0.9760, entropy_marginal: -23.4792, entropy_mean: -38.7362\n",
      "output_dc0 tensor([0, 0, 0, 1, 1, 0, 1, 2], device='cuda:0') dc_0 tensor([0, 0, 0, 1, 1, 0, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 0, 1, 2, 2, 0, 1], device='cuda:0') mse tensor(0.4715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[2000/2104], d_loss: 0.6021, c_loss: 0.0326, g_loss: 4.1714, g_loss_a: 4.1651, KL_F&N: 0.7649, KL_F&R: 1.5463, entropy_marginal: -20.8684, entropy_mean: -29.9968\n",
      "output_dc0 tensor([0, 1, 2, 1, 0, 0, 1, 0], device='cuda:0') dc_0 tensor([0, 1, 2, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 0, 0, 0, 0, 0, 1], device='cuda:0') mse tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[3/5],Step[2100/2104], d_loss: 0.5594, c_loss: 0.0001, g_loss: 1.9542, g_loss_a: 1.9541, KL_F&N: 0.6781, KL_F&R: 1.1159, entropy_marginal: -21.8017, entropy_mean: -35.0472\n",
      "output_dc0 tensor([2, 2, 2, 1, 0, 1, 1, 0], device='cuda:0') dc_0 tensor([2, 2, 2, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 0, 1, 1, 0, 2, 2, 0], device='cuda:0') mse tensor(0.4259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[100/2104], d_loss: 0.1873, c_loss: 0.0001, g_loss: 3.0496, g_loss_a: 3.0495, KL_F&N: 0.4062, KL_F&R: 1.7240, entropy_marginal: -24.2544, entropy_mean: -39.2830\n",
      "output_dc0 tensor([2, 1, 0, 2, 2, 2, 0, 1], device='cuda:0') dc_0 tensor([2, 2, 0, 2, 2, 2, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 2, 2, 0, 2, 0, 0], device='cuda:0') mse tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[200/2104], d_loss: 1.1381, c_loss: 0.4621, g_loss: 2.0777, g_loss_a: 2.0759, KL_F&N: 1.4256, KL_F&R: 0.4808, entropy_marginal: -18.8727, entropy_mean: -24.1767\n",
      "output_dc0 tensor([1, 1, 0, 2, 2, 2, 2, 0], device='cuda:0') dc_0 tensor([1, 1, 0, 2, 2, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 2, 2, 2, 0, 0], device='cuda:0') mse tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[300/2104], d_loss: 1.3854, c_loss: 0.0000, g_loss: 5.0951, g_loss_a: 5.0951, KL_F&N: 0.1228, KL_F&R: 0.3988, entropy_marginal: -19.0793, entropy_mean: -32.7728\n",
      "output_dc0 tensor([0, 2, 0, 0, 2, 0, 2, 2], device='cuda:0') dc_0 tensor([0, 2, 0, 0, 2, 0, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 2, 1, 0, 2, 2, 2], device='cuda:0') mse tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[400/2104], d_loss: 0.3656, c_loss: 0.0447, g_loss: 3.3228, g_loss_a: 3.3178, KL_F&N: 1.1855, KL_F&R: 2.3210, entropy_marginal: -26.0055, entropy_mean: -35.6260\n",
      "output_dc0 tensor([2, 0, 1, 2, 2, 1, 1, 2], device='cuda:0') dc_0 tensor([2, 2, 1, 2, 2, 1, 1, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 1, 0, 2, 1, 2, 1], device='cuda:0') mse tensor(0.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[500/2104], d_loss: 0.4718, c_loss: 0.4502, g_loss: 2.2458, g_loss_a: 2.2364, KL_F&N: 0.4588, KL_F&R: 1.4144, entropy_marginal: -18.4034, entropy_mean: -26.3968\n",
      "output_dc0 tensor([2, 2, 1, 0, 2, 2, 0, 1], device='cuda:0') dc_0 tensor([2, 2, 1, 0, 2, 2, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 2, 1, 1, 2, 0, 2], device='cuda:0') mse tensor(0.5718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[600/2104], d_loss: 0.1969, c_loss: 0.0001, g_loss: 2.9235, g_loss_a: 2.9234, KL_F&N: 1.6166, KL_F&R: 2.2747, entropy_marginal: -19.4648, entropy_mean: -31.2834\n",
      "output_dc0 tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0') dc_0 tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 0, 0, 1, 2, 1], device='cuda:0') mse tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[700/2104], d_loss: 0.4876, c_loss: 0.0450, g_loss: 6.9726, g_loss_a: 6.9530, KL_F&N: 3.0393, KL_F&R: 3.7142, entropy_marginal: -18.3608, entropy_mean: -25.1185\n",
      "output_dc0 tensor([2, 1, 2, 1, 1, 0, 0, 1], device='cuda:0') dc_0 tensor([2, 1, 2, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 2, 2, 1, 1, 0, 0], device='cuda:0') mse tensor(0.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[800/2104], d_loss: 0.6669, c_loss: 0.0000, g_loss: 4.2848, g_loss_a: 4.2848, KL_F&N: 1.9163, KL_F&R: 1.6313, entropy_marginal: -23.7919, entropy_mean: -37.4155\n",
      "output_dc0 tensor([1, 1, 2, 0, 0, 0, 0, 2], device='cuda:0') dc_0 tensor([1, 1, 2, 0, 0, 0, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 1, 2, 0, 0, 2, 2], device='cuda:0') mse tensor(0.4640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[900/2104], d_loss: 0.0768, c_loss: 0.0002, g_loss: 4.4793, g_loss_a: 4.4790, KL_F&N: 1.2111, KL_F&R: 2.7778, entropy_marginal: -21.4186, entropy_mean: -34.8486\n",
      "output_dc0 tensor([1, 0, 1, 0, 2, 0, 2, 1], device='cuda:0') dc_0 tensor([1, 0, 1, 0, 2, 0, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 2, 2, 2, 1, 2, 1], device='cuda:0') mse tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1000/2104], d_loss: 0.1877, c_loss: 0.0024, g_loss: 4.8029, g_loss_a: 4.8006, KL_F&N: 1.2919, KL_F&R: 2.5878, entropy_marginal: -22.4548, entropy_mean: -36.3322\n",
      "output_dc0 tensor([1, 2, 0, 2, 0, 0, 0, 2], device='cuda:0') dc_0 tensor([1, 2, 0, 2, 0, 0, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 2, 1, 2, 0, 0, 1], device='cuda:0') mse tensor(0.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1100/2104], d_loss: 0.5595, c_loss: 0.0016, g_loss: 1.9656, g_loss_a: 1.9642, KL_F&N: 0.6478, KL_F&R: 1.1157, entropy_marginal: -20.6415, entropy_mean: -31.7698\n",
      "output_dc0 tensor([1, 2, 0, 1, 0, 0, 2, 2], device='cuda:0') dc_0 tensor([1, 2, 0, 1, 0, 0, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 1, 1, 0, 0, 2, 1], device='cuda:0') mse tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1200/2104], d_loss: 0.4579, c_loss: 0.0000, g_loss: 3.1926, g_loss_a: 3.1926, KL_F&N: 1.4401, KL_F&R: 2.2241, entropy_marginal: -23.3005, entropy_mean: -38.3748\n",
      "output_dc0 tensor([0, 0, 1, 1, 2, 0, 2, 0], device='cuda:0') dc_0 tensor([0, 0, 1, 1, 2, 0, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 0, 2, 1, 2, 0, 0], device='cuda:0') mse tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1300/2104], d_loss: 0.4800, c_loss: 0.0001, g_loss: 5.1082, g_loss_a: 5.1081, KL_F&N: 0.5931, KL_F&R: 1.4791, entropy_marginal: -17.2588, entropy_mean: -28.5625\n",
      "output_dc0 tensor([0, 2, 0, 2, 2, 0, 1, 0], device='cuda:0') dc_0 tensor([0, 2, 0, 2, 2, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 2, 1, 1, 2, 1, 1], device='cuda:0') mse tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1400/2104], d_loss: 0.5359, c_loss: 0.0013, g_loss: 2.9511, g_loss_a: 2.9498, KL_F&N: 0.7701, KL_F&R: 1.3443, entropy_marginal: -22.2533, entropy_mean: -34.9386\n",
      "output_dc0 tensor([1, 0, 0, 2, 0, 2, 2, 0], device='cuda:0') dc_0 tensor([1, 0, 0, 2, 0, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 2, 0, 0, 1, 0, 1], device='cuda:0') mse tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1500/2104], d_loss: 1.0208, c_loss: 0.0002, g_loss: 3.7776, g_loss_a: 3.7773, KL_F&N: 0.2822, KL_F&R: 1.4708, entropy_marginal: -23.6239, entropy_mean: -35.7849\n",
      "output_dc0 tensor([0, 1, 0, 2, 1, 2, 1, 0], device='cuda:0') dc_0 tensor([0, 1, 0, 2, 1, 2, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 0, 1, 2, 2, 2, 2], device='cuda:0') mse tensor(0.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1600/2104], d_loss: 0.2993, c_loss: 0.0005, g_loss: 3.7967, g_loss_a: 3.7962, KL_F&N: 0.4235, KL_F&R: 1.5637, entropy_marginal: -20.3457, entropy_mean: -33.6156\n",
      "output_dc0 tensor([0, 1, 1, 0, 2, 2, 2, 0], device='cuda:0') dc_0 tensor([0, 1, 1, 0, 2, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 2, 1, 0, 2, 1, 1], device='cuda:0') mse tensor(0.4571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1700/2104], d_loss: 0.8816, c_loss: 0.0000, g_loss: 5.1370, g_loss_a: 5.1370, KL_F&N: 0.1199, KL_F&R: 0.6237, entropy_marginal: -21.0610, entropy_mean: -34.2725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dc0 tensor([2, 1, 1, 0, 0, 0, 1, 1], device='cuda:0') dc_0 tensor([2, 1, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 0, 2, 1, 0, 1], device='cuda:0') mse tensor(0.4634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1800/2104], d_loss: 0.4335, c_loss: 0.0043, g_loss: 2.6027, g_loss_a: 2.5989, KL_F&N: 1.2896, KL_F&R: 2.2360, entropy_marginal: -23.3351, entropy_mean: -35.1890\n",
      "output_dc0 tensor([2, 2, 1, 0, 1, 0, 1, 0], device='cuda:0') dc_0 tensor([2, 2, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 0, 1, 0, 0, 2, 1], device='cuda:0') mse tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[1900/2104], d_loss: 0.4274, c_loss: 0.0000, g_loss: 2.5823, g_loss_a: 2.5823, KL_F&N: 0.9033, KL_F&R: 1.8055, entropy_marginal: -27.1443, entropy_mean: -43.5665\n",
      "output_dc0 tensor([1, 2, 0, 0, 0, 1, 2, 2], device='cuda:0') dc_0 tensor([1, 2, 0, 0, 0, 1, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0') mse tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[2000/2104], d_loss: 1.3790, c_loss: 0.0002, g_loss: 4.5952, g_loss_a: 4.5951, KL_F&N: 0.5509, KL_F&R: 0.7469, entropy_marginal: -22.2330, entropy_mean: -36.5153\n",
      "output_dc0 tensor([0, 1, 0, 1, 2, 1, 0, 0], device='cuda:0') dc_0 tensor([0, 1, 0, 1, 2, 1, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 1, 1, 0, 0, 0, 1], device='cuda:0') mse tensor(0.4187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[4/5],Step[2100/2104], d_loss: 0.2437, c_loss: 0.0008, g_loss: 4.6047, g_loss_a: 4.6039, KL_F&N: 0.5985, KL_F&R: 1.7539, entropy_marginal: -27.6473, entropy_mean: -42.2666\n",
      "output_dc0 tensor([1, 2, 1, 1, 2, 1, 2, 1], device='cuda:0') dc_0 tensor([1, 2, 1, 1, 2, 1, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 2, 1, 2, 0, 2, 2], device='cuda:0') mse tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[100/2104], d_loss: 1.4029, c_loss: 0.0800, g_loss: 3.9930, g_loss_a: 3.9912, KL_F&N: 1.4846, KL_F&R: 0.9435, entropy_marginal: -22.4100, entropy_mean: -31.0710\n",
      "output_dc0 tensor([1, 0, 2, 2, 0, 2, 0, 0], device='cuda:0') dc_0 tensor([1, 0, 2, 2, 0, 2, 0, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 1, 1, 1, 0, 2, 0], device='cuda:0') mse tensor(0.4524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[200/2104], d_loss: 0.7738, c_loss: 0.0005, g_loss: 3.6567, g_loss_a: 3.6562, KL_F&N: 0.1598, KL_F&R: 0.7940, entropy_marginal: -21.4562, entropy_mean: -33.3576\n",
      "output_dc0 tensor([0, 0, 0, 2, 1, 1, 0, 0], device='cuda:0') dc_0 tensor([1, 0, 0, 2, 1, 1, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 0, 0, 2, 0, 0, 0], device='cuda:0') mse tensor(0.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[300/2104], d_loss: 2.1893, c_loss: 0.6360, g_loss: 5.2343, g_loss_a: 5.2315, KL_F&N: 0.4803, KL_F&R: 0.1384, entropy_marginal: -16.0548, entropy_mean: -26.0422\n",
      "output_dc0 tensor([1, 1, 0, 1, 0, 0, 2, 1], device='cuda:0') dc_0 tensor([1, 1, 0, 1, 0, 0, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 2, 2, 2, 0, 2], device='cuda:0') mse tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[400/2104], d_loss: 0.4066, c_loss: 0.0009, g_loss: 1.9952, g_loss_a: 1.9944, KL_F&N: 0.5477, KL_F&R: 1.5055, entropy_marginal: -22.6855, entropy_mean: -33.0930\n",
      "output_dc0 tensor([2, 2, 2, 2, 0, 0, 2, 0], device='cuda:0') dc_0 tensor([2, 2, 2, 2, 0, 0, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 0, 2, 1, 1, 2], device='cuda:0') mse tensor(0.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[500/2104], d_loss: 0.5457, c_loss: 0.4908, g_loss: 2.6639, g_loss_a: 2.6360, KL_F&N: 1.8152, KL_F&R: 1.6362, entropy_marginal: -19.5333, entropy_mean: -26.2618\n",
      "output_dc0 tensor([0, 0, 2, 0, 1, 2, 1, 1], device='cuda:0') dc_0 tensor([0, 0, 2, 0, 1, 2, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 1, 0, 1, 1, 2, 0], device='cuda:0') mse tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[600/2104], d_loss: 0.4685, c_loss: 0.0003, g_loss: 3.1761, g_loss_a: 3.1758, KL_F&N: 0.9735, KL_F&R: 1.2826, entropy_marginal: -24.7486, entropy_mean: -37.7760\n",
      "output_dc0 tensor([2, 1, 1, 0, 2, 1, 2, 1], device='cuda:0') dc_0 tensor([2, 1, 1, 0, 2, 1, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 1, 0, 0, 0, 2, 0], device='cuda:0') mse tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[700/2104], d_loss: 0.5838, c_loss: 0.0001, g_loss: 2.8268, g_loss_a: 2.8267, KL_F&N: 1.4098, KL_F&R: 1.9597, entropy_marginal: -28.0675, entropy_mean: -41.8550\n",
      "output_dc0 tensor([0, 1, 1, 2, 2, 0, 2, 1], device='cuda:0') dc_0 tensor([0, 1, 1, 2, 2, 0, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 0, 0, 1, 1, 2, 2], device='cuda:0') mse tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[800/2104], d_loss: 1.0423, c_loss: 0.0001, g_loss: 4.0227, g_loss_a: 4.0226, KL_F&N: 0.3716, KL_F&R: 0.5454, entropy_marginal: -24.7341, entropy_mean: -40.6821\n",
      "output_dc0 tensor([0, 0, 2, 1, 2, 1, 2, 2], device='cuda:0') dc_0 tensor([0, 0, 2, 1, 2, 1, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 2, 2, 1, 2, 0, 0], device='cuda:0') mse tensor(0.4690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[900/2104], d_loss: 0.1986, c_loss: 0.0008, g_loss: 3.6511, g_loss_a: 3.6503, KL_F&N: 1.0957, KL_F&R: 2.2174, entropy_marginal: -20.2555, entropy_mean: -33.1762\n",
      "output_dc0 tensor([1, 1, 2, 1, 2, 0, 2, 2], device='cuda:0') dc_0 tensor([1, 1, 2, 1, 2, 0, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 2, 0, 0, 1, 1, 0, 1], device='cuda:0') mse tensor(0.4436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1000/2104], d_loss: 0.1192, c_loss: 0.0005, g_loss: 4.4860, g_loss_a: 4.4855, KL_F&N: 1.0377, KL_F&R: 2.0745, entropy_marginal: -23.1724, entropy_mean: -36.8323\n",
      "output_dc0 tensor([2, 1, 1, 1, 0, 2, 2, 0], device='cuda:0') dc_0 tensor([2, 1, 1, 1, 0, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 2, 0, 0, 2, 1, 0], device='cuda:0') mse tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1100/2104], d_loss: 0.9364, c_loss: 0.0000, g_loss: 3.0179, g_loss_a: 3.0179, KL_F&N: 0.4255, KL_F&R: 0.7964, entropy_marginal: -22.8547, entropy_mean: -37.7539\n",
      "output_dc0 tensor([2, 2, 1, 2, 2, 1, 1, 1], device='cuda:0') dc_0 tensor([2, 2, 1, 2, 2, 2, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0') mse tensor(0.3432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1200/2104], d_loss: 0.3622, c_loss: 0.3579, g_loss: 3.1986, g_loss_a: 3.1650, KL_F&N: 0.6428, KL_F&R: 1.2803, entropy_marginal: -24.5802, entropy_mean: -33.8074\n",
      "output_dc0 tensor([2, 0, 0, 1, 2, 2, 0, 2], device='cuda:0') dc_0 tensor([2, 0, 0, 1, 2, 2, 0, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 1, 0, 0, 1, 0, 0], device='cuda:0') mse tensor(0.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1300/2104], d_loss: 0.2621, c_loss: 0.0231, g_loss: 4.1386, g_loss_a: 4.1281, KL_F&N: 1.5015, KL_F&R: 1.9721, entropy_marginal: -21.0997, entropy_mean: -32.4218\n",
      "output_dc0 tensor([2, 0, 0, 0, 1, 2, 2, 0], device='cuda:0') dc_0 tensor([2, 0, 0, 0, 1, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 1, 1, 0, 2, 0, 0, 0], device='cuda:0') mse tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1400/2104], d_loss: 0.9034, c_loss: 0.0005, g_loss: 6.1064, g_loss_a: 6.1059, KL_F&N: 0.2196, KL_F&R: 0.5874, entropy_marginal: -27.5794, entropy_mean: -40.8486\n",
      "output_dc0 tensor([1, 1, 2, 1, 0, 1, 2, 2], device='cuda:0') dc_0 tensor([1, 1, 2, 1, 0, 1, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 0, 1, 2, 1, 2, 2, 1], device='cuda:0') mse tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1500/2104], d_loss: 0.4097, c_loss: 0.0000, g_loss: 3.6388, g_loss_a: 3.6388, KL_F&N: 0.9346, KL_F&R: 1.9427, entropy_marginal: -27.5456, entropy_mean: -43.1602\n",
      "output_dc0 tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0') dc_0 tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 1, 1, 0, 2, 0, 0, 0], device='cuda:0') mse tensor(0.5399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1600/2104], d_loss: 0.2878, c_loss: 0.0021, g_loss: 4.9095, g_loss_a: 4.9076, KL_F&N: 1.9371, KL_F&R: 2.6416, entropy_marginal: -33.7425, entropy_mean: -46.3888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dc0 tensor([0, 0, 1, 0, 1, 2, 2, 0], device='cuda:0') dc_0 tensor([0, 0, 1, 0, 1, 2, 2, 0], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 1, 0, 2, 1, 2, 1, 1], device='cuda:0') mse tensor(0.4779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1700/2104], d_loss: 1.0266, c_loss: 0.0222, g_loss: 3.1437, g_loss_a: 3.1315, KL_F&N: 0.1751, KL_F&R: 0.4308, entropy_marginal: -21.5268, entropy_mean: -35.6317\n",
      "output_dc0 tensor([2, 1, 0, 2, 0, 0, 2, 2], device='cuda:0') dc_0 tensor([2, 1, 0, 2, 0, 0, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([1, 2, 2, 1, 1, 1, 1, 0], device='cuda:0') mse tensor(0.4413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1800/2104], d_loss: 0.6010, c_loss: 0.0010, g_loss: 3.7604, g_loss_a: 3.7595, KL_F&N: 0.7570, KL_F&R: 0.9719, entropy_marginal: -23.8219, entropy_mean: -35.7390\n",
      "output_dc0 tensor([1, 1, 2, 0, 0, 0, 2, 2], device='cuda:0') dc_0 tensor([1, 1, 2, 0, 0, 0, 2, 2], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 0, 2, 2, 1, 2, 2, 2], device='cuda:0') mse tensor(0.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[1900/2104], d_loss: 2.0815, c_loss: 0.0010, g_loss: 6.0843, g_loss_a: 6.0832, KL_F&N: 0.5896, KL_F&R: 0.2581, entropy_marginal: -18.8172, entropy_mean: -30.9725\n",
      "output_dc0 tensor([0, 2, 1, 1, 2, 1, 2, 1], device='cuda:0') dc_0 tensor([0, 2, 1, 1, 2, 1, 2, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([0, 0, 2, 0, 2, 0, 2, 2], device='cuda:0') mse tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[2000/2104], d_loss: 0.1080, c_loss: 0.0000, g_loss: 3.6024, g_loss_a: 3.6024, KL_F&N: 0.9441, KL_F&R: 2.3537, entropy_marginal: -20.6874, entropy_mean: -32.5694\n",
      "output_dc0 tensor([2, 0, 1, 0, 2, 2, 1, 1], device='cuda:0') dc_0 tensor([2, 0, 1, 0, 2, 2, 1, 1], device='cuda:0')\n",
      "None\n",
      "output_dcR0 tensor([2, 2, 1, 2, 1, 1, 2, 1], device='cuda:0') mse tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch[5/5],Step[2100/2104], d_loss: 0.3022, c_loss: 0.0000, g_loss: 2.9766, g_loss_a: 2.9766, KL_F&N: 0.9250, KL_F&R: 2.1425, entropy_marginal: -24.7620, entropy_mean: -40.7577\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "global args\n",
    "print(args)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not os.path.exists(args.model_g_path):\n",
    "    os.makedirs(args.model_g_path)\n",
    "if not os.path.exists(args.model_d_path):\n",
    "    os.makedirs(args.model_d_path)\n",
    "if not os.path.exists(args.model_c_path):\n",
    "    os.makedirs(args.model_c_path)\n",
    "if not os.path.exists(args.sample_path):\n",
    "    os.makedirs(args.sample_path)\n",
    "# Networks====================================================\n",
    "generator = Generator(args.db, args.z_dim, args.cc_dim, args.dc_dim)\n",
    "discriminator = Discriminator(args.db, args.featu_dim)\n",
    "classifier = Classifier(args.db, args.cc_dim, args.dc_dim)\n",
    "# Optimizers\n",
    "g_optimizer = optim.Adam(generator.parameters(), args.lrG, [args.beta1, args.beta2])\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), args.lrD, [args.beta1, args.beta2])\n",
    "c_optimizer = optim.Adam(classifier.parameters(), args.lrD, [args.beta1, args.beta2])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    classifier.cuda()\n",
    "\n",
    "mse_loss = 0\n",
    "\n",
    "total_step = len(data_loader)\n",
    "loss_val_d = [] \n",
    "loss_val_g = []\n",
    "loss_val_c = []\n",
    "loss_val_kl = []\n",
    "loss_val_kl_2 = []\n",
    "for epoch in range(args.num_epochs):\n",
    "    epoch_loss_d = []\n",
    "    epoch_loss_g = []\n",
    "    epoch_loss_c = []\n",
    "    epoch_kl = []\n",
    "    epoch_kl_2 = []\n",
    "    for i, images in enumerate(data_loader):\n",
    "        # ===================== Make some images =====================#\n",
    "        images = to_variable(images)\n",
    "        batch_size = images.size(0) # batch size =16\n",
    "        noise = to_variable(torch.randn(batch_size, args.z_dim))# noise for training\n",
    "        cc = to_variable(gen_cc(batch_size, args.cc_dim))\n",
    "        dc = to_variable(gen_dc(batch_size, args.dc_dim))\n",
    "        fake_images = generator(torch.cat((cc, dc, noise),1))\n",
    "        images = images.float().to(device)#\n",
    "        # ========MSE loss=================\n",
    "        MSEloss = nn.MSELoss()\n",
    "        if batch_size == 8:\n",
    "            mseloss1 = MSEloss( fake_images[0,:,:,:], fake_images[1,:,:,:] )\n",
    "            mseloss2 = MSEloss( fake_images[1,:,:,:], fake_images[2,:,:,:] )\n",
    "            mseloss3 = MSEloss( fake_images[2,:,:,:], fake_images[3,:,:,:] )\n",
    "            mseloss4 = MSEloss( fake_images[3,:,:,:], fake_images[4,:,:,:] )\n",
    "            mseloss5 = MSEloss( fake_images[4,:,:,:], fake_images[5,:,:,:] )\n",
    "            mseloss6 = MSEloss( fake_images[5,:,:,:], fake_images[6,:,:,:] )\n",
    "            mseloss7 = MSEloss( fake_images[6,:,:,:], fake_images[7,:,:,:] )\n",
    "            mse_loss = mseloss1+mseloss2+mseloss3+mseloss4+mseloss5+mseloss6+mseloss7\n",
    "        \n",
    "        # ===================== Train D =====================#\n",
    "        d_output_real, real_featu = discriminator(images)\n",
    "        d_output_fake, fake_featu = discriminator(fake_images)\n",
    "        d_loss_a = -torch.mean(torch.log(d_output_real[:,0]) + torch.log(1 - d_output_fake[:,0]))\n",
    "        \n",
    "        #===== measure KL div of fake_feature and noise ======#\n",
    "        fake_featu = F.log_softmax(fake_featu)\n",
    "        sof_noice = F.softmax(noise)\n",
    "        feature_loss = nn.KLDivLoss()(fake_featu, sof_noice)\n",
    "        epoch_kl.append(feature_loss.item())\n",
    "        real_featu = F.softmax(real_featu)\n",
    "        feature_loss_2 = nn.KLDivLoss()(fake_featu, real_featu)\n",
    "        epoch_kl_2.append(feature_loss_2.item())\n",
    "        # Optimization\n",
    "        d_loss = d_loss_a #+ feature_loss\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        d_optimizer.step()\n",
    "        epoch_loss_d.append(d_loss.item())\n",
    "        \n",
    "        # ===================== Train C =====================#\n",
    "        c_output_real = classifier(images)\n",
    "        c_output_fake = classifier(fake_images)\n",
    "        # compute Entropy Loss\n",
    "        output_cc = c_output_fake[:, 0:args.cc_dim]\n",
    "        c_loss_cc = torch.mean((((output_cc - 0.0) / 0.5) ** 2))\n",
    "        \n",
    "        output_dc = c_output_fake[:, args.cc_dim:]\n",
    "        output_dcR = c_output_real[:, args.cc_dim:]\n",
    "        output_dcR0 = torch.argmax(output_dcR, dim=1)\n",
    "        ppp_mean = torch.mean(output_dc, dim=0, keepdim=True)\n",
    "        ppp_mean_R = torch.mean(output_dcR, dim=0, keepdim=True)\n",
    "        entropy_marginal = get_entropy_1D(ppp_mean)\n",
    "        entropy_marginal_R = get_entropy_1D(ppp_mean_R)\n",
    "        entropy_mean = torch.mean(get_entropy_2D(output_dc))\n",
    "        entropy_mean_R = torch.mean(get_entropy_2D(output_dcR))\n",
    "        c_loss_entpy = -0.1*entropy_marginal_R +  0.03*entropy_mean_R\n",
    "            \n",
    "        # cross entropy loss of dc and out_dc========================\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        dc_0 = torch.argmax(dc, dim=1)\n",
    "        output_dc0 = torch.argmax(output_dc, dim=1)\n",
    "        c_loss_d = loss(output_dc, dc_0) #- 0.1*entropy_marginal\n",
    "        \n",
    "        c_loss_dc = c_loss_d\n",
    "\n",
    "        c_loss = args.continuous_weight*c_loss_cc + 1.0 * c_loss_dc #- 0.1* mse_loss\n",
    "        \n",
    "        # Optimization\n",
    "        classifier.zero_grad()\n",
    "        c_loss.backward(retain_graph=True)\n",
    "        c_optimizer.step()\n",
    "        epoch_loss_c.append(c_loss.item())\n",
    "        \n",
    "        # ===================== Train G =====================#\n",
    "        fake_images = generator(torch.cat((cc, dc, noise),1))\n",
    "        # ========MSE loss=================\n",
    "        MSEloss = nn.MSELoss()\n",
    "        if batch_size == 8:\n",
    "            mseloss1 = MSEloss( fake_images[0,:,:,:], fake_images[1,:,:,:] )\n",
    "            mseloss2 = MSEloss( fake_images[1,:,:,:], fake_images[2,:,:,:] )\n",
    "            mseloss3 = MSEloss( fake_images[2,:,:,:], fake_images[3,:,:,:] )\n",
    "            mseloss4 = MSEloss( fake_images[3,:,:,:], fake_images[4,:,:,:] )\n",
    "            mseloss5 = MSEloss( fake_images[4,:,:,:], fake_images[5,:,:,:] )\n",
    "            mseloss6 = MSEloss( fake_images[5,:,:,:], fake_images[6,:,:,:] )\n",
    "            mseloss7 = MSEloss( fake_images[6,:,:,:], fake_images[7,:,:,:] )\n",
    "            mse_loss = mseloss1+mseloss2+mseloss3+mseloss4+mseloss5+mseloss6+mseloss7\n",
    "            \n",
    "        d_output_fake, fake_featu = discriminator(fake_images)\n",
    "        c_output_fake = classifier(fake_images)\n",
    "        g_loss_a = -torch.mean(torch.log(d_output_fake[:,0])) # the quality score of fake image\n",
    "        \n",
    "        # Re-compute Entropy Loss\n",
    "        c_output_real = classifier(images)\n",
    "        c_output_fake = classifier(fake_images)\n",
    "        \n",
    "        output_cc = c_output_fake[:, 0:args.cc_dim]\n",
    "        c_loss_cc = torch.mean((((output_cc - 0.0) / 0.5) ** 2))\n",
    "        \n",
    "        output_dc = c_output_fake[:, args.cc_dim:]\n",
    "        output_dcR = c_output_real[:, args.cc_dim:]\n",
    "        \n",
    "        ppp_mean = torch.mean(output_dc, dim=0, keepdim=True)\n",
    "        ppp_mean_R = torch.mean(output_dcR, dim=0, keepdim=True)\n",
    "        \n",
    "        entropy_marginal = get_entropy_1D(ppp_mean)\n",
    "        entropy_marginal_R = get_entropy_1D(ppp_mean_R)\n",
    "        \n",
    "        entropy_mean = torch.mean(get_entropy_2D(output_dc))\n",
    "        entropy_mean_R = torch.mean(get_entropy_2D(output_dcR))\n",
    "        \n",
    "        c_loss_entpy = -0.1*entropy_marginal_R +  0.03*entropy_mean_R\n",
    "        dc_0 = torch.argmax(dc, dim=1)\n",
    "        c_loss_d = loss(output_dc, dc_0) #- 0.1*entropy_marginal\n",
    "        c_loss_dc = c_loss_d\n",
    "\n",
    "        g_loss = g_loss_a + args.continuous_weight*c_loss_cc + 1.0*c_loss_dc #- 0.1*mse_loss\n",
    "        # Optimization\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        epoch_loss_g.append(g_loss.item())\n",
    "        \n",
    "        #========== print log ==============\n",
    "        if (i + 1) % args.log_step == 0:\n",
    "            print(print(\"output_dc0\",output_dc0, \"dc_0\", dc_0))\n",
    "            print(\"output_dcR0\",output_dcR0, \"mse\",mse_loss)\n",
    "            #print(\"output_dc\",output_dc)\n",
    "            print('Epoch[%d/%d],Step[%d/%d], d_loss: %.4f, c_loss: %.4f, g_loss: %.4f, g_loss_a: %.4f, KL_F&N: %.4f, KL_F&R: %.4f, entropy_marginal: %.4f, entropy_mean: %.4f'\n",
    "                  % (epoch + 1, args.num_epochs, i + 1, total_step, d_loss.data, c_loss.data, g_loss.data, g_loss_a.data, \n",
    "                     feature_loss.data, feature_loss_2.data, entropy_marginal.data, entropy_mean.data)) \n",
    "        if (i + 1) % args.sample_step == 0:\n",
    "            #====== cc for test ==========\n",
    "            tmp = np.zeros((args.sample_size, args.cc_dim))\n",
    "            for k in range(3): # cycle 16行就要循环16次，和下面的16一样\n",
    "                #tmp[k * 10:(k + 1) * 10, 0] = np.linspace(0, 0, 10)\n",
    "                tmp[k * 10:(k + 1) * 10, 0] = np.linspace(-2, 2, 10)\n",
    "                \n",
    "            cc = to_variable(torch.Tensor(tmp))\n",
    "            #print(cc.shape)\n",
    "            #====== dc for test ==========\n",
    "            tmp = np.zeros((args.sample_size, args.dc_dim))\n",
    "            for k in range(3): # cycle 修改这里是行数（类数）\n",
    "                tmp[k * 10:(k + 1) * 10, k] = 1\n",
    "            dc = to_variable(torch.Tensor(tmp))\n",
    "            rands = torch.rand\n",
    "            fixed_noise = to_variable(torch.ones(args.sample_size, args.z_dim))\n",
    "            a = torch.cat((cc, dc, fixed_noise), 1)\n",
    "            fake_images = generator(a)\n",
    "            torchvision.utils.save_image(fake_images.data,\n",
    "                                    os.path.join(args.sample_path, #args.sample_path\n",
    "                                        'generated-%d-%d.png' % (epoch + 1, i + 1)), nrow=10)#列数\n",
    "#             torchvision.utils.save_image(fake_images.data,os.path.join('F:/Jupyter Notebook/Deep8/results/result single imgs',\n",
    "#                                                                        'generated-%d-%d.png' % (epoch + 1, i + 1)))\n",
    "     \n",
    "    loss_val_d.append(sum(epoch_loss_d)/len(epoch_loss_d))\n",
    "    loss_val_g.append(sum(epoch_loss_g)/len(epoch_loss_g))\n",
    "    loss_val_c.append(sum(epoch_loss_c)/len(epoch_loss_c))\n",
    "    loss_val_kl.append(sum(epoch_kl)/len(epoch_kl))\n",
    "    loss_val_kl_2.append(sum(epoch_kl_2)/len(epoch_kl_2))\n",
    "\n",
    "    # save the model parameters for each epoch\n",
    "    g_path = os.path.join(args.model_g_path, 'generator-%d.pkl' % (epoch + 1))\n",
    "    d_path = os.path.join(args.model_d_path, 'discriminator-%d.pkl' % (epoch + 1))\n",
    "    c_path = os.path.join(args.model_c_path, 'classifier-%d.pkl' % (epoch + 1))\n",
    "    torch.save(generator.state_dict(), g_path)\n",
    "    torch.save(discriminator.state_dict(), d_path)\n",
    "    torch.save(classifier.state_dict(), c_path)\n",
    "# plot loss curves   \n",
    "plt.plot(loss_val_d) # blue\n",
    "plt.plot(loss_val_g) # orange\n",
    "plt.plot(loss_val_c) # green\n",
    "plt.show()\n",
    "plt.plot(loss_val_kl) # fake & noise (in Adam)\n",
    "plt.show()\n",
    "plt.plot(loss_val_kl_2) # fake & real\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100, 16])\n"
     ]
    }
   ],
   "source": [
    "PATH_G = \"./models/models_g_128/generator-27.pkl\"\n",
    "generator.load_state_dict(torch.load(PATH_G), strict=False)\n",
    "generator.eval()\n",
    "\n",
    "tmp = np.zeros((args.sample_size, args.cc_dim))\n",
    "for k in range(10): # cycle 16行就要循环16次，和下面的16一样\n",
    "    tmp[k * 10:(k + 1) * 10, 0] = np.linspace(-2, 2, 10)\n",
    "    tmp[k * 10:(k + 1) * 10, 1] = np.linspace(0, 0, 10)\n",
    "cc2 = to_variable(torch.Tensor(tmp))\n",
    "tmp = np.zeros((args.sample_size, args.dc_dim))\n",
    "for k in range(10): # cycle 修改这里是行数（类数）\n",
    "    tmp[k * 10:(k + 1) * 10, k] = 1\n",
    "dc = to_variable(torch.Tensor(tmp))\n",
    "print(cc2.shape)\n",
    "print(dc.shape)\n",
    "print(fixed_noise.shape)\n",
    "\n",
    "a2 = torch.cat((cc2, dc, fixed_noise), 1)\n",
    "fake_images = generator(a2)\n",
    "\n",
    "torchvision.utils.save_image(fake_images.data,\n",
    "                        os.path.join(args.sample_path_2, #args.sample_path\n",
    "                            'generated-%d-%d.png' % (epoch + 1, i + 1)), nrow=10)#列数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (3): Conv2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (9): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============= Load Trained D and C =================\n",
    "PATH_D = \"./models/models_d_128/discriminator-5.pkl\"\n",
    "discriminator = Discriminator(args.db, args.featu_dim)\n",
    "discriminator.load_state_dict(torch.load(PATH_D), strict=False)\n",
    "discriminator.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (3): Conv2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (6): Conv2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    (9): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_C = \"./models/models_c_128/classifier-5.pkl\"\n",
    "classifier = Classifier(args.db,args.cc_dim, args.dc_dim)\n",
    "classifier.load_state_dict(torch.load(PATH_C), strict=False)\n",
    "classifier.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current row 0 is finished\n",
      "current row 1 is finished\n",
      "current row 2 is finished\n",
      "current row 3 is finished\n",
      "current row 4 is finished\n",
      "current row 5 is finished\n",
      "current row 6 is finished\n",
      "current row 7 is finished\n",
      "current row 8 is finished\n",
      "current row 9 is finished\n",
      "current row 10 is finished\n",
      "current row 11 is finished\n",
      "current row 12 is finished\n",
      "current row 13 is finished\n",
      "current row 14 is finished\n",
      "current row 15 is finished\n",
      "current row 16 is finished\n",
      "current row 17 is finished\n",
      "current row 18 is finished\n",
      "current row 19 is finished\n",
      "current row 20 is finished\n",
      "current row 21 is finished\n",
      "current row 22 is finished\n",
      "current row 23 is finished\n",
      "current row 24 is finished\n",
      "current row 25 is finished\n",
      "current row 26 is finished\n",
      "current row 27 is finished\n",
      "current row 28 is finished\n",
      "current row 29 is finished\n",
      "current row 30 is finished\n",
      "current row 31 is finished\n",
      "current row 32 is finished\n",
      "current row 33 is finished\n",
      "current row 34 is finished\n",
      "current row 35 is finished\n",
      "current row 36 is finished\n",
      "current row 37 is finished\n",
      "current row 38 is finished\n",
      "current row 39 is finished\n",
      "current row 40 is finished\n",
      "current row 41 is finished\n",
      "current row 42 is finished\n",
      "current row 43 is finished\n",
      "current row 44 is finished\n",
      "current row 45 is finished\n",
      "current row 46 is finished\n",
      "current row 47 is finished\n",
      "current row 48 is finished\n",
      "current row 49 is finished\n",
      "current row 50 is finished\n",
      "current row 51 is finished\n",
      "current row 52 is finished\n",
      "current row 53 is finished\n",
      "current row 54 is finished\n",
      "current row 55 is finished\n",
      "current row 56 is finished\n",
      "(5416, 7)\n",
      "(5415, 7)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 320000000\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale((args.image_size, args.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5, ))])\n",
    "if torch.cuda.is_available():\n",
    "    #generator.cuda()\n",
    "    #discriminator.cuda()\n",
    "    classifier.cuda()\n",
    "\n",
    "images = Image.open('D:/KPC-F838-3_2016_07_12_024/024x8_3.tif')\n",
    "#images = Image.open('F:/Jupyter Notebook/Deep8/HE/KPCL159-2-0082-HE.tif')\n",
    "\n",
    "height = 128\n",
    "width = 128\n",
    "imgwidth, imgheight = images.size\n",
    "\n",
    "rows = np.random.rand(1, 7)\n",
    "\n",
    "for i in range(imgheight//height): #整除\n",
    "    for j in range(imgwidth//width): #整除\n",
    "        box = (j*width, i*height, (j+1)*width, (i+1)*height)\n",
    "        #print(box)\n",
    "        image_patch = images.crop(box)\n",
    "        \n",
    "        images_tsr = transform(image_patch)\n",
    "        images_tsr = torch.unsqueeze(images_tsr, 0)\n",
    "        images_tsr = images_tsr.cuda()\n",
    "        \n",
    "        c_output_real = classifier(images_tsr)\n",
    "        output_dc = c_output_real[:, args.cc_dim : args.cc_dim+args.dc_dim]\n",
    "        #print(label)\n",
    "        \n",
    "        label = output_dc.cpu().data\n",
    "        one_row = np.append(label, box)\n",
    "        one_row = np.expand_dims(one_row, axis=0)\n",
    "        \n",
    "        rows = np.append(rows, one_row, axis=0)\n",
    "    print(\"current row\",i,\"is finished\")\n",
    "print(rows.shape)\n",
    "rows = np.delete(rows, 0, 0)\n",
    "print(rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16827, 128, 128, 3)\n",
      "(16827, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale((args.image_size, args.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5,), (0.5, 0.5, 0.5, ))])\n",
    "\n",
    "dataset=np.load(\"./kpc/data1/128.npy\")\n",
    "print(dataset.shape)\n",
    "dataset = np.moveaxis(dataset, 3, 1)\n",
    "print(dataset.shape)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 8, 128, 128, 3)\n",
      "(11000, 3, 128, 128)\n",
      "torch.Size([11000, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "if args.db=='kpc128': # kpc64\n",
    "    #dataset = ImageFolder(args.image_path, transform)# modify the path\n",
    "    dataset = np.load(\"./kpc/data0/slice128_Block2_11K.npy\")\n",
    "    print(dataset.shape)####################\n",
    "    dataset = dataset[:, 0, :, :, :]\n",
    "    dataset = np.moveaxis(dataset, 3, 1)\n",
    "    print(dataset.shape)\n",
    "    dataset.astype(float)\n",
    "    dataset = dataset/255\n",
    "    dataset = torch.from_numpy(dataset)\n",
    "    #dataset = dataset.to(device)\n",
    "    print(dataset.shape)\n",
    "    \n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16828, 5)\n",
      "(16827, 5)\n"
     ]
    }
   ],
   "source": [
    "rows = np.random.rand(1, args.featu_dim+1)\n",
    "\n",
    "for epoch in range(args.test_epochs):\n",
    "    for i, images in enumerate(data_loader):\n",
    "        images = to_variable(images)        \n",
    "        if torch.cuda.is_available():\n",
    "            discriminator.cuda()\n",
    "            classifier.cuda()\n",
    "        images = images.float()\n",
    "        images = images.to(device)\n",
    "        \n",
    "        d_output_real, real_featu = discriminator(images)\n",
    "        c_output_real = classifier(images)\n",
    "        #print(d_output_real.shape)\n",
    "        \n",
    "        real_fake = d_output_real[:,0]\n",
    "        output_dc = c_output_real[:, args.cc_dim:]\n",
    "        featu = real_featu.cpu().data.numpy()\n",
    "        #print('featu.shape=',featu.shape)\n",
    "        \n",
    "        label = torch.argmax(output_dc, dim=1)\n",
    "        label = label.cpu().data.numpy()\n",
    "        #print('label.shape=',label.shape)\n",
    "        \n",
    "        one_row = np.append(featu, label)\n",
    "        one_row = np.expand_dims(one_row, axis=0)\n",
    "        #print(one_row,one_row.shape)\n",
    "        \n",
    "        rows = np.append(rows, one_row, axis=0)\n",
    "    print(rows.shape)\n",
    "    \n",
    "    rows = np.delete(rows, 0, 0)\n",
    "    print(rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(rows).to_csv(\"./csv/label and feature 21-4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
